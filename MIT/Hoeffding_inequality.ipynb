{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17307215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.704\n",
      "Hoeffding 95% CI = [0.661, 0.747]  (± 0.043)\n",
      "Pull counts per arm: [355 365 280]\n",
      "Estimated means:      [0.603 0.603 0.575]\n",
      "Cumulative regret at horizon: 5.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ---------- (A) Confidence interval for test accuracy via Hoeffding ----------\n",
    "\n",
    "def hoeffding_ci_for_accuracy(y_true, y_pred, delta=0.05):\n",
    "    \"\"\"\n",
    "    Distribution-free CI for true accuracy using Hoeffding.\n",
    "    Assumes i.i.d. test samples; 0/1 correctness is bounded in [0,1].\n",
    "    \"\"\"\n",
    "    n = len(y_true)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    rad = np.sqrt(np.log(2.0/delta)/(2.0*n))\n",
    "    lower = max(0.0, acc - rad)\n",
    "    upper = min(1.0, acc + rad)\n",
    "    return acc, (lower, upper), rad\n",
    "\n",
    "# Synthetic binary classification task\n",
    "rng = np.random.default_rng(0)\n",
    "n = 4000\n",
    "d = 5\n",
    "X = rng.normal(size=(n, d))\n",
    "w = rng.normal(size=(d,))\n",
    "logits = X @ w\n",
    "probs = 1/(1+np.exp(-logits))\n",
    "y = (rng.uniform(size=n) < probs).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1000, random_state=0, stratify=y)\n",
    "\n",
    "clf = LogisticRegression(max_iter=2000).fit(X_train, y_train)\n",
    "y_hat = clf.predict(X_test)\n",
    "\n",
    "acc, (lo, hi), rad = hoeffding_ci_for_accuracy(y_test, y_hat, delta=0.05)\n",
    "print(f\"Test accuracy = {acc:.3f}\")\n",
    "print(f\"Hoeffding 95% CI = [{lo:.3f}, {hi:.3f}]  (± {rad:.3f})\")\n",
    "\n",
    "# Optional: compare to binomial proportion CIs (not distribution-free but often tighter):\n",
    "# from statsmodels.stats.proportion import proportion_confint\n",
    "# k = (y_test == y_hat).sum()\n",
    "# n = len(y_test)\n",
    "# wilson_lo, wilson_hi = proportion_confint(k, n, alpha=0.05, method='wilson')\n",
    "# print(f\"Wilson 95% CI   = [{wilson_lo:.3f}, {wilson_hi:.3f}]\")\n",
    "\n",
    "# ---------- (B) Small UCB1 demo (Hoeffding-based optimism) ----------\n",
    "\n",
    "def ucb1(K=3, horizon=1000, means=(0.2, 0.5, 0.6), seed=1):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n_pulls = np.zeros(K, dtype=int)\n",
    "    sum_rewards = np.zeros(K, dtype=float)\n",
    "    rewards = []\n",
    "\n",
    "    # Initialize: pull each arm once\n",
    "    for a in range(K):\n",
    "        r = float(rng.random() < means[a])\n",
    "        n_pulls[a] += 1\n",
    "        sum_rewards[a] += r\n",
    "        rewards.append(r)\n",
    "\n",
    "    for t in range(K+1, horizon+1):\n",
    "        ucb = np.zeros(K)\n",
    "        for a in range(K):\n",
    "            mu_hat = sum_rewards[a] / n_pulls[a]\n",
    "            bonus = np.sqrt(2*np.log(t) / n_pulls[a])  # from Hoeffding\n",
    "            ucb[a] = mu_hat + bonus\n",
    "        a_star = int(np.argmax(ucb))\n",
    "        r = float(rng.random() < means[a])\n",
    "        n_pulls[a_star] += 1\n",
    "        sum_rewards[a_star] += r\n",
    "        rewards.append(r)\n",
    "\n",
    "    cum_reward = np.cumsum(rewards)\n",
    "    regret = np.arange(1, horizon+1)*max(means) - cum_reward\n",
    "    return cum_reward, regret, n_pulls, sum_rewards / np.maximum(1, n_pulls)\n",
    "\n",
    "cum_reward, regret, counts, est_means = ucb1()\n",
    "print(f\"Pull counts per arm: {counts}\")\n",
    "print(f\"Estimated means:      {np.round(est_means,3)}\")\n",
    "print(f\"Cumulative regret at horizon: {regret[-1]:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5a39f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.957\n",
      "Test  accuracy: 0.947\n",
      "Hoeffding 95% CI for TRUE accuracy: [0.767, 1.000]  (± 0.180)\n",
      "95% lower-bound guarantee on true accuracy: 0.767\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# --------------------------\n",
    "# 1) Data + 90/10 split\n",
    "# --------------------------\n",
    "data = load_breast_cancer()\n",
    "X = data['data']\n",
    "y = data['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.10, random_state=0, stratify=y\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# 2) Train model\n",
    "# --------------------------\n",
    "clf = LogisticRegression(solver='liblinear', max_iter=2000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "train_acc = accuracy_score(y_train, clf.predict(X_train))\n",
    "test_acc  = accuracy_score(y_test,  clf.predict(X_test))\n",
    "\n",
    "# --------------------------\n",
    "# 3) Hoeffding CI on TEST accuracy\n",
    "# --------------------------\n",
    "def hoeffding_ci_for_accuracy(y_true, y_pred, delta=0.05):\n",
    "    \"\"\"\n",
    "    Distribution-free CI for true accuracy using Hoeffding.\n",
    "    Assumes i.i.d. test samples; 0/1 correctness is bounded in [0,1].\n",
    "    \"\"\"\n",
    "    n = len(y_true)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    rad = np.sqrt(np.log(2.0/delta) / (2.0 * n))  # <-- key formula\n",
    "    lower = max(0.0, acc - rad)\n",
    "    upper = min(1.0, acc + rad)\n",
    "    return acc, (lower, upper), rad\n",
    "\n",
    "acc, (lo, hi), rad = hoeffding_ci_for_accuracy(y_test, clf.predict(X_test), delta=0.05)\n",
    "\n",
    "print(f\"Train accuracy: {train_acc:.3f}\")\n",
    "print(f\"Test  accuracy: {test_acc:.3f}\")\n",
    "print(f\"Hoeffding 95% CI for TRUE accuracy: [{lo:.3f}, {hi:.3f}]  (± {rad:.3f})\")\n",
    "\n",
    "# --------------------------\n",
    "# 4) Generalization bound (statement)\n",
    "# --------------------------\n",
    "# With probability at least 1 - delta over the draw of the TEST set:\n",
    "# | true_accuracy - test_accuracy | <= sqrt( ln(2/delta) / (2 * n_test) )\n",
    "# Equivalently, a conservative lower-bound guarantee on true accuracy is:\n",
    "true_acc_lower_bound = max(0.0, test_acc - rad)\n",
    "print(f\"95% lower-bound guarantee on true accuracy: {true_acc_lower_bound:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16a59b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
